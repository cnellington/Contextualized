@article{lengerich_automated_2022,
	title = {Automated {Interpretable} {Discovery} of {Heterogeneous} {Treatment} {Effectiveness}: {A} {COVID}-19 {Case} {Study}},
	issn = {1532-0464},
	url = {https://www.sciencedirect.com/science/article/pii/S1532046422001022},
	doi = {10.1016/j.jbi.2022.104086},
	abstract = {Testing multiple treatments for heterogeneous (varying) effectiveness with
respect to many underlying risk factors requires many pairwise tests; we
would like to instead automatically discover and visualize patient
archetypes and predictors of treatment effectiveness using multitask
machine learning. In this paper, we present a method to estimate these
heterogeneous treatment effects with an interpretable hierarchical
framework that uses additive models to visualize expected treatment
benefits as a function of patient factors (identifying personalized
treatment benefits) and concurrent treatments (identifying combinatorial
treatment benefits). This method achieves state-of-the-art predictive
power for COVID-19 in-hospital mortality and interpretable identification
of heterogeneous treatment benefits. We first validate this method on the
large public MIMIC-IV dataset of ICU patients to test recovery of
heterogeneous treatment effects. Next we apply this method to a
proprietary dataset of over 3000 patients hospitalized for COVID-19, and
find evidence of heterogeneous treatment effectiveness predicted largely
by indicators of inflammation and thrombosis risk: patients with few
indicators of thrombosis risk benefit most from treatments against
inflammation, while patients with few indicators of inflammation risk
benefit most from treatments against thrombosis. This approach provides an
automated methodology to discover heterogeneous and individualized
effectiveness of treatments.},
	journal = {J. Biomed. Inform.},
	author = {Lengerich, Benjamin J. and Nunnally, Mark E. and Aphinyanaphongs, Yin and Ellington, Caleb and Caruana, Rich},
	month = apr,
	year = {2022},
	keywords = {COVID-19, Heterogeneous Treatment Effects, Interpretable Machine Learning, notion, Personalized Medicine},
	pages = {104086},
}

@article{stoica_contextual_2020,
	title = {Contextual {Parameter} {Generation} for {Knowledge} {Graph} {Link} {Prediction}},
	volume = {34},
	copyright = {Copyright (c) 2020 Association for the Advancement of Artificial Intelligence},
	issn = {2374-3468},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/5693},
	doi = {10.1609/aaai.v34i03.5693},
	abstract = {We consider the task of knowledge graph link prediction. Given a question consisting of a source entity and a relation (e.g., Shakespeare and BornIn), the objective is to predict the most likely answer entity (e.g., England). Recent approaches tackle this problem by learning entity and relation embeddings. However, they often constrain the relationship between these embeddings to be additive (i.e., the embeddings are concatenated and then processed by a sequence of linear functions and element-wise non-linearities). We show that this type of interaction significantly limits representational power. For example, such models cannot handle cases where a different projection of the source entity is used for each relation. We propose to use contextual parameter generation to address this limitation. More specifically, we treat relations as the context in which source entities are processed to produce predictions, by using relation embeddings to generate the parameters of a model operating over source entity embeddings. This allows models to represent more complex interactions between entities and relations. We apply our method on two existing link prediction methods, including the current state-of-the-art, resulting in significant performance gains and establishing a new state-of-the-art for this task. These gains are achieved while also reducing convergence time by up to 28 times.},
	language = {en},
	number = {03},
	urldate = {2022-09-24},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	author = {Stoica, George and Stretcu, Otilia and Platanios, Emmanouil Antonios and Mitchell, Tom and Póczos, Barnabás},
	month = apr,
	year = {2020},
	pages = {3000--3008},
}

@misc{lengerich_contextualized_2023,
	title = {Contextualized {Machine} {Learning}},
	url = {http://arxiv.org/abs/2310.11340},
	doi = {10.48550/arXiv.2310.11340},
	abstract = {We examine Contextualized Machine Learning (ML), a paradigm for learning heterogeneous and context-dependent effects. Contextualized ML estimates heterogeneous functions by applying deep learning to the meta-relationship between contextual information and context-specific parametric models. This is a form of varying-coefficient modeling that unifies existing frameworks including cluster analysis and cohort modeling by introducing two reusable concepts: a context encoder which translates sample context into model parameters, and sample-specific model which operates on sample predictors. We review the process of developing contextualized models, nonparametric inference from contextualized models, and identifiability conditions of contextualized models. Finally, we present the open-source PyTorch package ContextualizedML.},
	urldate = {2023-11-02},
	publisher = {arXiv},
	author = {Lengerich, Benjamin J. and Ellington, Caleb N. and Rubbi, Andrea and Kellis, Manolis and Xing, Eric P.},
	month = oct,
	year = {2023},
	note = {arXiv:2310.11340 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{ellington_contextualized_2023,
	title = {Contextualized {Networks} {Reveal} {Heterogeneous} {Transcriptomic} {Regulation} in {Tumors} at {Sample}-{Specific} {Resolution}},
	copyright = {© 2023, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2023.12.01.569658v1},
	doi = {10.1101/2023.12.01.569658},
	abstract = {Cancers are shaped by somatic mutations, microenvironment, and patient background, each altering gene expression and regulation in complex ways, resulting in heterogeneous cellular states and dynamics. Inferring gene regulatory network (GRN) models from expression data can help characterize this regulation-driven heterogeneity, but network inference requires many statistical samples, traditionally limiting GRNs to cluster-level analyses that ignore intra-cluster heterogeneity. We propose to move beyond cluster-based analyses by using contextualized learning, a multi-task learning paradigm which allows us to infer sample-specific models using phenotypic, molecular, and environmental information pertinent to the model, encoded as the model's "context" to be conditioned on. We unify three network model classes (Correlation, Markov, Neighborhood) and estimate context-specific GRNs for 7997 tumors across 25 tumor types, with each network contextualized by copy number and driver mutation profiles, tumor microenvironment, and patient demographics. Contextualized GRNs provide a structured view of expression dynamics at sample-specific resolution, which reveal co-expression modules in correlation networks (CNs), as well as cliques and independent regulatory elements in Markov Networks (MNs) and Neighborhood Regression Networks (NNs). Our generative modeling approach allows us to predict GRNs for unseen tumor types based on a pan-cancer model of how somatic mutations affect gene regulation. Finally, contextualized networks enable GRN-based precision oncology, explaining known biomarkers in terms of network-mediated effects, and leading to novel subtypings for thyroid, brain, and gastrointestinal tumors that improve survival prognosis.},
	language = {en},
	urldate = {2023-12-06},
	publisher = {bioRxiv},
	author = {Ellington, Caleb N. and Lengerich, Benjamin J. and Watkins, Thomas BK and Yang, Jiekun and Xiao, Hanxi and Kellis, Manolis and Xing, Eric P.},
	month = dec,
	year = {2023},
	note = {Pages: 2023.12.01.569658
Section: New Results},
	file = {Full Text PDF:/Users/calebellington/Zotero/storage/TBK7SS4L/Ellington et al. - 2023 - Contextualized Networks Reveal Heterogeneous Trans.pdf:application/pdf},
}

@misc{lengerich_notmad_2021,
	title = {{NOTMAD}: {Estimating} {Bayesian} {Networks} with {Sample}-{Specific} {Structures} and {Parameters}},
	shorttitle = {{NOTMAD}},
	url = {http://arxiv.org/abs/2111.01104},
	doi = {10.48550/arXiv.2111.01104},
	abstract = {Context-specific Bayesian networks (i.e. directed acyclic graphs, DAGs) identify context-dependent relationships between variables, but the non-convexity induced by the acyclicity requirement makes it difficult to share information between context-specific estimators (e.g. with graph generator functions). For this reason, existing methods for inferring context-specific Bayesian networks have favored breaking datasets into subsamples, limiting statistical power and resolution, and preventing the use of multidimensional and latent contexts. To overcome this challenge, we propose NOTEARS-optimized Mixtures of Archetypal DAGs (NOTMAD). NOTMAD models context-specific Bayesian networks as the output of a function which learns to mix archetypal networks according to sample context. The archetypal networks are estimated jointly with the context-specific networks and do not require any prior knowledge. We encode the acyclicity constraint as a smooth regularization loss which is back-propagated to the mixing function; in this way, NOTMAD shares information between context-specific acyclic graphs, enabling the estimation of Bayesian network structures and parameters at even single-sample resolution. We demonstrate the utility of NOTMAD and sample-specific network inference through analysis and experiments, including patient-specific gene expression networks which correspond to morphological variation in cancer.},
	urldate = {2024-03-14},
	publisher = {arXiv},
	author = {Lengerich, Benjamin J. and Ellington, Caleb N. and Aragam, Bryon and Xing, Eric P. and Kellis, Manolis},
	month = nov,
	year = {2021},
	note = {arXiv:2111.01104 [cs, stat]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, notion, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/calebellington/Zotero/storage/LI6RW6BP/Lengerich et al. - 2021 - NOTMAD Estimating Bayesian Networks with Sample-S.pdf:application/pdf},
}

@article{hastie_varying-coefficient_1993,
	title = {Varying-{Coefficient} {Models}},
	volume = {55},
	copyright = {© 1993 Royal Statistical Society},
	issn = {2517-6161},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.2517-6161.1993.tb01939.x},
	doi = {10.1111/j.2517-6161.1993.tb01939.x},
	abstract = {We explore a class of regression and generalized regression models in which the coefficients are allowed to vary as smooth functions of other variables. General algorithms are presented for estimating the models flexibly and some examples are given. This class of models ties together generalized additive models and dynamic generalized linear models into one common framework. When applied to the proportional hazards model for survival data, this approach provides a new way of modelling departures from the proportional hazards assumption.},
	language = {en},
	number = {4},
	urldate = {2024-03-14},
	journal = {Journal of the Royal Statistical Society: Series B (Methodological)},
	author = {Hastie, Trevor and Tibshirani, Robert},
	year = {1993},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.2517-6161.1993.tb01939.x},
	keywords = {dynamic generalized linear models, generalized additive models, generalized linear models, regression, smoothing, splines, survival analysis},
	pages = {757--779},
}

@misc{al-shedivat_contextual_2020,
	title = {Contextual {Explanation} {Networks}},
	url = {http://arxiv.org/abs/1705.10301},
	doi = {10.48550/arXiv.1705.10301},
	abstract = {Modern learning algorithms excel at producing accurate but complex models of the data. However, deploying such models in the real-world requires extra care: we must ensure their reliability, robustness, and absence of undesired biases. This motivates the development of models that are equally accurate but can be also easily inspected and assessed beyond their predictive performance. To this end, we introduce contextual explanation networks (CEN)---a class of architectures that learn to predict by generating and utilizing intermediate, simplified probabilistic models. Specifically, CENs generate parameters for intermediate graphical models which are further used for prediction and play the role of explanations. Contrary to the existing post-hoc model-explanation tools, CENs learn to predict and to explain simultaneously. Our approach offers two major advantages: (i) for each prediction valid, instance-specific explanation is generated with no computational overhead and (ii) prediction via explanation acts as a regularizer and boosts performance in data-scarce settings. We analyze the proposed framework theoretically and experimentally. Our results on image and text classification and survival analysis tasks demonstrate that CENs are not only competitive with the state-of-the-art methods but also offer additional insights behind each prediction, that can be valuable for decision support. We also show that while post-hoc methods may produce misleading explanations in certain cases, CENs are consistent and allow to detect such cases systematically.},
	urldate = {2024-03-14},
	publisher = {arXiv},
	author = {Al-Shedivat, Maruan and Dubey, Avinava and Xing, Eric P.},
	month = sep,
	year = {2020},
	note = {arXiv:1705.10301 [cs, stat]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: 48 pages, 18 figures, to appear in JMLR},
	file = {arXiv Fulltext PDF:/Users/calebellington/Zotero/storage/YQ7UNNG2/Al-Shedivat et al. - 2020 - Contextual Explanation Networks.pdf:application/pdf},
}

@misc{lengerich_discriminative_2022,
	title = {Discriminative {Subtyping} of {Lung} {Cancers} from {Histopathology} {Images} via {Contextual} {Deep} {Learning}},
	copyright = {© 2022, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	url = {https://www.medrxiv.org/content/10.1101/2020.06.25.20140053v2},
	doi = {10.1101/2020.06.25.20140053},
	abstract = {Summarizing multiple data modalities into a parsimonious cancer “subtype” is difficult because the most informative representation of each patient’s disease is not observed. We propose to model these latent summaries as discriminative subtypes: sample representations which induce accurate and interpretable sample-specific models for downstream predictions. In this way, discriminative subtypes, which are shared between data modalities, can be estimated from one data modality and optimized according to the predictions induced in another modality. We apply this approach to lung cancer by training a deep neural network to predict discriminative subtypes from histopathology images, and use these predicted subtypes to generate models which classify adenocarcinoma, squamous cell carcinoma, and healthy tissue based on transcriptomic signatures. In this way, we optimize the latent discriminative subtypes through induced prediction loss, and the discriminative subtypes are interpreted with standard interpretation of transcriptomic predictive models. Our framework achieves state-of-the-art classification accuracy (F1-score of 0.97) and identifies discriminative subtypes which link histopathology images to transcriptomic explanations without requiring pre-specification of morphological patterns or transcriptomic processes.},
	language = {en},
	urldate = {2024-03-14},
	publisher = {medRxiv},
	author = {Lengerich, Benjamin J. and Al-Shedivat, Maruan and Alavi, Amir and Williams, Jennifer and Labbaki, Sami and Xing, Eric P.},
	month = nov,
	year = {2022},
	note = {ISSN: 2014-0053
Pages: 2020.06.25.20140053},
	file = {Full Text PDF:/Users/calebellington/Zotero/storage/AT6CEHUA/Lengerich et al. - 2022 - Discriminative Subtyping of Lung Cancers from Hist.pdf:application/pdf},
}

@misc{al-shedivat_personalized_2018,
	title = {Personalized {Survival} {Prediction} with {Contextual} {Explanation} {Networks}},
	url = {http://arxiv.org/abs/1801.09810},
	doi = {10.48550/arXiv.1801.09810},
	abstract = {Accurate and transparent prediction of cancer survival times on the level of individual patients can inform and improve patient care and treatment practices. In this paper, we design a model that concurrently learns to accurately predict patient-specific survival distributions and to explain its predictions in terms of patient attributes such as clinical tests or assessments. Our model is flexible and based on a recurrent network, can handle various modalities of data including temporal measurements, and yet constructs and uses simple explanations in the form of patient- and time-specific linear regression. For analysis, we use two publicly available datasets and show that our networks outperform a number of baselines in prediction while providing a way to inspect the reasons behind each prediction.},
	urldate = {2024-03-14},
	publisher = {arXiv},
	author = {Al-Shedivat, Maruan and Dubey, Avinava and Xing, Eric P.},
	month = jan,
	year = {2018},
	note = {arXiv:1801.09810 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
	annote = {Comment: Machine Learning for Healthcare Workshop, NIPS 2017},
	file = {arXiv Fulltext PDF:/Users/calebellington/Zotero/storage/YBY26XEW/Al-Shedivat et al. - 2018 - Personalized Survival Prediction with Contextual E.pdf:application/pdf},
}

@misc{deuschel_contextualized_2023,
	title = {Contextualized {Policy} {Recovery}: {Modeling} and {Interpreting} {Medical} {Decisions} with {Adaptive} {Imitation} {Learning}},
	shorttitle = {Contextualized {Policy} {Recovery}},
	url = {http://arxiv.org/abs/2310.07918},
	doi = {10.48550/arXiv.2310.07918},
	abstract = {Interpretable policy learning seeks to estimate intelligible decision policies from observed actions; however, existing models fall short by forcing a tradeoff between accuracy and interpretability. This tradeoff limits data-driven interpretations of human decision-making process. e.g. to audit medical decisions for biases and suboptimal practices, we require models of decision processes which provide concise descriptions of complex behaviors. Fundamentally, existing approaches are burdened by this tradeoff because they represent the underlying decision process as a universal policy, when in fact human decisions are dynamic and can change drastically with contextual information. Thus, we propose Contextualized Policy Recovery (CPR), which re-frames the problem of modeling complex decision processes as a multi-task learning problem in which complex decision policies are comprised of context-specific policies. CPR models each context-specific policy as a linear observation-to-action mapping, and generates new decision models \${\textbackslash}textit\{on-demand\}\$ as contexts are updated with new observations. CPR is compatible with fully offline and partially observable decision environments, and can be tailored to incorporate any recurrent black-box model or interpretable decision model. We assess CPR through studies on simulated and real data, achieving state-of-the-art performance on the canonical tasks of predicting antibiotic prescription in intensive care units (\$+22{\textbackslash}\%\$ AUROC vs. previous SOTA) and predicting MRI prescription for Alzheimer's patients (\$+7.7{\textbackslash}\%\$ AUROC vs. previous SOTA). With this improvement in predictive performance, CPR closes the accuracy gap between interpretable and black-box methods for policy learning, allowing high-resolution exploration and analysis of context-specific decision models.},
	urldate = {2023-11-02},
	publisher = {arXiv},
	author = {Deuschel, Jannik and Ellington, Caleb N. and Lengerich, Benjamin J. and Luo, Yingtao and Friederich, Pascal and Xing, Eric P.},
	month = oct,
	year = {2023},
	note = {arXiv:2310.07918 [cs, stat]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/calebellington/Zotero/storage/AJ8XNWW6/Deuschel et al. - 2023 - Contextualized Policy Recovery Modeling and Inter.pdf:application/pdf},
}

@article{fan_statistical_1999,
	title = {Statistical estimation in varying coefficient models},
	volume = {27},
	issn = {0090-5364, 2168-8966},
	url = {https://projecteuclid.org/journals/annals-of-statistics/volume-27/issue-5/Statistical-estimation-in-varying-coefficient-models/10.1214/aos/1017939139.full},
	doi = {10.1214/aos/1017939139},
	abstract = {Varying coefficient models are a useful extension of classical linear models. They arise naturally when one wishes to examine how regression coefficients change over different groups characterized by certain covariates such as age. The appeal of these models is that the coef .cient functions can easily be estimated via a simple local regression.This yields a simple one-step estimation procedure. We show that such a one-step method cannot be optimal when different coefficient functions admit different degrees of smoothness. This drawback can be repaired by using our proposed two-step estimation procedure.The asymptotic mean-squared error for the two-step procedure is obtained and is shown to achieve the optimal rate of convergence. A few simulation studies show that the gain by the two-step procedure can be quite substantial.The methodology is illustrated by an application to an environmental data set.},
	number = {5},
	urldate = {2022-06-27},
	journal = {The Annals of Statistics},
	author = {Fan, Jianqing and Zhang, Wenyang},
	month = oct,
	year = {1999},
	note = {Publisher: Institute of Mathematical Statistics},
	keywords = {62G07, 62J12, local linear fit, mean-squared errors, Optimal rate of convergence, personalization, statistics, varying coefficient models},
	pages = {1491--1518},
}

@article{kuijjer_estimating_2019,
	title = {Estimating {Sample}-{Specific} {Regulatory} {Networks}},
	volume = {14},
	issn = {2589-0042},
	doi = {10.1016/j.isci.2019.03.021},
	abstract = {Biological systems are driven by intricate interactions among molecules. Many methods have been developed that draw on large numbers of expression samples to infer connections between genes (or their products). The result is an aggregate network representing a single estimate for the likelihood of each interaction, or "edge," in the network. Although informative, aggregate models fail to capture population heterogeneity. Here we propose a method to reverse engineer sample-specific networks from aggregate networks. We demonstrate our approach in several contexts, including simulated, yeast microarray, and human lymphoblastoid cell line RNA sequencing data. We use these sample-specific networks to study changes in network topology across time and to characterize shifts in gene regulation that were not apparent in the expression data. We believe that generating sample-specific networks will greatly facilitate the application of network methods to large, complex, and heterogeneous multi-omic datasets, supporting the emerging field of precision network medicine.},
	language = {eng},
	journal = {iScience},
	author = {Kuijjer, Marieke Lydia and Tung, Matthew George and Yuan, GuoCheng and Quackenbush, John and Glass, Kimberly},
	month = apr,
	year = {2019},
	pmid = {30981959},
	pmcid = {PMC6463816},
	keywords = {Bioinformatics, Biological Sciences, Complex Systems},
	pages = {226--240},
	file = {Full Text:/Users/calebellington/Zotero/storage/MLXVELW9/Kuijjer et al. - 2019 - Estimating Sample-Specific Regulatory Networks.pdf:application/pdf},
}

@article{kolar_estimating_2010,
	title = {Estimating time-varying networks},
	volume = {4},
	issn = {1932-6157},
	url = {http://arxiv.org/abs/0812.5087},
	doi = {10.1214/09-AOAS308},
	abstract = {Stochastic networks are a plausible representation of the relational information among entities in dynamic systems such as living cells or social communities. While there is a rich literature in estimating a static or temporally invariant network from observation data, little has been done toward estimating time-varying networks from time series of entity attributes. In this paper we present two new machine learning methods for estimating time-varying networks, which both build on a temporally smoothed \$l\_1\$-regularized logistic regression formalism that can be cast as a standard convex-optimization problem and solved efficiently using generic solvers scalable to large networks. We report promising results on recovering simulated time-varying networks. For real data sets, we reverse engineer the latent sequence of temporally rewiring political networks between Senators from the US Senate voting records and the latent evolving regulatory networks underlying 588 genes across the life cycle of Drosophila melanogaster from the microarray time course.},
	number = {1},
	urldate = {2024-03-26},
	journal = {The Annals of Applied Statistics},
	author = {Kolar, Mladen and Song, Le and Ahmed, Amr and Xing, Eric P.},
	month = mar,
	year = {2010},
	note = {arXiv:0812.5087 [q-bio, stat]},
	keywords = {Quantitative Biology - Molecular Networks, Quantitative Biology - Quantitative Methods, Statistics - Applications, Statistics - Machine Learning, Statistics - Methodology},
	annote = {Comment: Published in at http://dx.doi.org/10.1214/09-AOAS308 the Annals of Applied Statistics (http://www.imstat.org/aoas/) by the Institute of Mathematical Statistics (http://www.imstat.org)},
	file = {arXiv Fulltext PDF:/Users/calebellington/Zotero/storage/9PS5EVN5/Kolar et al. - 2010 - Estimating time-varying networks.pdf:application/pdf},
}


@article{wang_bayesian_2022,
	title = {Bayesian {Edge} {Regression} in {Undirected} {Graphical} {Models} to {Characterize} {Interpatient} {Heterogeneity} in {Cancer}},
	volume = {117},
	issn = {0162-1459},
	doi = {10.1080/01621459.2021.2000866},
	abstract = {It is well-established that interpatient heterogeneity in cancer may significantly affect genomic data analyses and in particular, network topologies. Most existing graphical model methods estimate a single population-level graph for genomic or proteomic network. In many investigations, these networks depend on patient-specific indicators that characterize the heterogeneity of individual networks across subjects with respect to subject-level covariates. Examples include assessments of how the network varies with patient-specific prognostic scores or comparisons of tumor and normal graphs while accounting for tumor purity as a continuous predictor. In this paper, we propose a novel edge regression model for undirected graphs, which estimates conditional dependencies as a function of subject-level covariates. We evaluate our model performance through simulation studies focused on comparing tumor and normal graphs while adjusting for tumor purity. In application to a dataset of proteomic measurements on plasma samples from patients with hepatocellular carcinoma (HCC), we ascertain how blood protein networks vary with disease severity, as measured by HepatoScore, a novel biomarker signature measuring disease severity. Our case study shows that the network connectivity increases with HepatoScore and a set of hub genes as well as important gene connections are identified under different HepatoScore, which may provide important biological insights to the development of precision therapies for HCC.},
	language = {eng},
	number = {538},
	journal = {Journal of the American Statistical Association},
	author = {Wang, Zeya and Kaseb, Ahmed O. and Amin, Hesham M. and Hassan, Manal M. and Wang, Wenyi and Morris, Jeffrey S.},
	year = {2022},
	pmid = {36090952},
	pmcid = {PMC9454401},
	keywords = {Bayesian adaptive shrinkage, Gene regulatory network, Tumor heterogeneity, Undirected graphical models, Non-static graph},
	pages = {533--546},
	file = {Accepted Version:/Users/calebellington/Zotero/storage/A7P25CK7/Wang et al. - 2022 - Bayesian Edge Regression in Undirected Graphical M.pdf:application/pdf},
}


@article{parikh_treegl_2011,
	title = {{TREEGL}: reverse engineering tree-evolving gene networks underlying developing biological lineages},
	volume = {27},
	issn = {1367-4803},
	url = {http://dx.doi.org/10.1093/bioinformatics/btr239},
	doi = {10.1093/bioinformatics/btr239},
	abstract = {MOTIVATION: Estimating gene regulatory networks over biological lineages
is central to a deeper understanding of how cells evolve during
development and differentiation. However, one challenge in estimating such
evolving networks is that their host cells not only contiguously evolve,
but also branch over time. For example, a stem cell evolves into two more
specialized daughter cells at each division, forming a tree of networks.
Another example is in a laboratory setting: a biologist may apply several
different drugs individually to malignant cancer cells to analyze the
effects of each drug on the cells; the cells treated by one drug may not
be intrinsically similar to those treated by another, but rather to the
malignant cancer cells they were derived from. RESULTS: We propose a novel
algorithm, Treegl, an ℓ(1) plus total variation penalized linear
regression method, to effectively estimate multiple gene networks
corresponding to cell types related by a tree-genealogy, based on only a
few samples from each cell type. Treegl takes advantage of the similarity
between related networks along the biological lineage, while at the same
time exposing sharp differences between the networks. We demonstrate that
our algorithm performs significantly better than existing methods via
simulation. Furthermore we explore an application to a breast cancer
dataset, and show that our algorithm is able to produce biologically valid
results that provide insight into the progression and reversion of breast
cancer cells. AVAILABILITY: Software will be available at
http://www.sailing.cs.cmu.edu/. CONTACT: epxing@cs.cmu.edu.},
	number = {13},
	journal = {Bioinformatics},
	author = {Parikh, Ankur P and Wu, Wei and Curtis, Ross E and Xing, Eric P},
	month = jul,
	year = {2011},
	pages = {i196--204},
}

@article{hothorn_partykit_2015,
	title = {partykit: {A} {Modular} {Toolkit} for {Recursive} {Partytioning} in {R}},
	volume = {16},
	issn = {1533-7928},
	shorttitle = {partykit},
	url = {http://jmlr.org/papers/v16/hothorn15a.html},
	abstract = {The R package partykit provides a flexible toolkit for learning, representing, summarizing, and visualizing a wide range of tree- structured regression and classification models. The functionality encompasses: (a) basic infrastructure for representing trees (inferred by any algorithm) so that unified print/plot/predict methods are available; (b) dedicated methods for trees with constant fits in the leaves (or terminal nodes) along with suitable coercion functions to create such trees (e.g., by rpart, RWeka, PMML); (c) a reimplementation of conditional inference trees (ctree, originally provided in the party package); (d) an extended reimplementation of model-based recursive partitioning (mob, also originally in party) along with dedicated methods for trees with parametric models in the leaves. Here, a brief overview of the package and its design is given while more detailed discussions of items (a)—(d) are available in vignettes accompanying the package.},
	number = {118},
	urldate = {2024-03-23},
	journal = {Journal of Machine Learning Research},
	author = {Hothorn, Torsten and Zeileis, Achim},
	year = {2015},
	keywords = {notion},
	pages = {3905--3909},
	file = {Full Text PDF:/Users/calebellington/Zotero/storage/S9N4P6K3/Hothorn and Zeileis - 2015 - partykit A Modular Toolkit for Recursive Partytio.pdf:application/pdf},
}


@inproceedings{kolar_sparsistent_2009,
	title = {Sparsistent {Learning} of {Varying}-coefficient {Models} with {Structural} {Changes}},
	volume = {22},
	url = {https://proceedings.neurips.cc/paper/2009/hash/7bcdf75ad237b8e02e301f4091fb6bc8-Abstract.html},
	abstract = {To estimate the changing structure of a varying-coefficient   varying-structure (VCVS) model remains an important and open problem   in dynamic system modelling, which includes learning trajectories of   stock prices, or uncovering the topology of an evolving gene   network. In this paper, we investigate sparsistent learning of a   sub-family of this model --- piecewise constant VCVS models. We   analyze two main issues in this problem: inferring time points where   structural changes occur and estimating model structure (i.e., model   selection) on each of the constant segments. We propose a two-stage   adaptive procedure, which first identifies jump points of structural   changes and then identifies relevant covariates to a response on   each of the segments. We provide an asymptotic analysis of the   procedure, showing that with the increasing sample size, number of   structural changes, and number of variables, the true model can be   consistently selected. We demonstrate the performance of the method   on synthetic data and apply it to the brain computer interface   dataset. We also consider how this applies to structure estimation   of time-varying probabilistic graphical models.},
	urldate = {2024-03-26},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Kolar, Mladen and Song, Le and Xing, Eric},
	year = {2009},
	file = {Full Text PDF:/Users/calebellington/Zotero/storage/NUTZZVA9/Kolar et al. - 2009 - Sparsistent Learning of Varying-coefficient Models.pdf:application/pdf},
}
