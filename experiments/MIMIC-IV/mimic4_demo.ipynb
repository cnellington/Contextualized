{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "from interpret.glassbox import ExplainableBoostingClassifier as ebc\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score as roc\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from interpret import show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Housekeeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/correlator/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3444: DtypeWarning: Columns (21,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,449,450,451,452,454,455,459,462,464,465,466,467,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,496,499,500,501,502,503,504,505,506,507,508,509,519,523,524,527,528,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,570,571,575,581,594,596,598,599,600,601,602,603,604,608,612,613,614,615,616,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,663,664,665,667,668,669,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,719,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800,801,802,803,804,805,806,807,808,809,810,811,812,813,814,815,816,817,818,819,820,823,836,838,840,842,843,846,847,848,849,850,851,852,853,862,872,873,874,875,876,877,878,879,880,881,885,889,890,897,898,899,900,901,902,903,904,905,906,907,908,909,910,911,912,913,914,915,916,917,918,919,920,922,923,924,925,926,927,928,929,930,934,935,936,937,939,941,946,947,956,957,958,959,960,961,962,963,964,965,966,967,968,977,991,992,993,994,995,999,1000,1001,1002,1004,1016,1017,1018,1019,1020,1021,1022,1023,1024,1025,1026,1027,1028,1029,1030,1031,1032,1033,1034,1035,1036,1037,1038,1039,1040,1041,1042,1043,1044,1045,1046,1048,1049,1050,1051,1052,1053,1054,1059,1062,1063,1064,1065,1066,1069,1070,1071,1072,1073,1074,1075,1076,1077,1078,1079,1080,1081,1082,1083,1084,1092,1093,1094,1095,1096,1097,1098,1099,1100,1101,1102,1103,1104,1105,1120,1121,1122,1123,1124,1125,1126,1127,1128,1129,1130,1131,1132,1133,1134,1135,1136,1137,1138,1139,1140,1148,1149,1150,1151,1152,1153,1154,1155,1156,1157,1158,1159,1160,1161,1162,1163,1164,1165,1166,1167,1168,1169,1170,1171,1172,1173,1174,1175,1176,1177,1178,1179,1180,1181,1182,1183,1184,1185,1186,1187,1188,1189,1190,1191,1192,1193,1194,1195,1196,1197,1198,1199,1200,1201,1202,1203,1204,1205,1206,1207,1208,1209,1210,1211,1212,1213,1214,1215,1216,1217,1218,1219,1220,1221,1222,1223,1224,1225,1226,1228,1232,1240,1245,1246,1247,1257,1262,1264,1266,1267,1268,1278,1279,1282,1283,1284,1286,1287,1288,1289,1291,1292,1293,1294,1295,1296,1302,1303,1304,1305,1307,1308,1309,1311,1312,1314,1315,1317,1318,1320,1334,1350,1364,1365,1366,1367,1368,1369,1370,1371,1372,1373,1374,1375,1376,1377,1378,1379,1380,1381,1382,1384,1390,1391,1392,1393,1394,1395,1396,1397,1398,1400,1401,1402,1403,1404,1405,1406,1409,1410,1411,1412,1413,1414,1422,1423,1439,1441,1443,1451,1463,1464,1476,1490,1491,1492,1514,1515,1566,1567,1568,1569,1570,1571,1572,1573,1574,1575,1577,1578,1581,1582,1583,1587,1588,1591,1592,1593,1594,1595,1596,1618,1656,1657,1658,1659,1660,1661,1663,1667,1674,1675,1676,1677,1678,1683,1684,1686,1687,1688,1689,1692,1693,1694,1695,1700,1701,1702,1703,1704,1705,1708,1709,1710,1711,1712,1713,1714,1715,1716,1717,1718,1721,1722,1723,1726,1727,1729,1730,1731,1732,1736,1737,1738,1739,1740,1741,1742,1743,1744,1745,1746,1747,1748,1749,1750,1751,1752,1753,1754,1755,1756,1757,1758,1759,1760,1761,1762,1763,1764,1765,1766,1768,1772,1775,1776,1778,1779,1780,1781,1782,1783,1784,1785,1786,1787,1788,1789,1790,1791,1792,1793,1797,1798,1799,1800,1801,1802,1803,1804,1805,1806,1812,1815,1816,1817,1818,1819,1820,1821,1822,1823,1824,1825,1826,1827,1828,1829,1830,1831,1832,1833,1843,1845,1849,1853,1857,1858,1859,1860,1861,1862,1863,1864,1865,1866,1867,1868,1869,1870,1871,1872,1873,1874,1875,1876,1877,1878,1879,1880,1881,1882,1883,1884,1891,1892,1893,1894,1895,1896,1897,1898,1899,1900,1901,1902,1903,1909,1916,1918,1919,1924,1926,1927,1928,1929,1930,1949,1953,1955,1957,1959,1960,1963,1964,1965,1968,1970,1971,1972,1973,1974,1975,1976,1978,1983,1998,1999,2000,2001,2002,2003,2004,2005,2006,2007,2009,2011,2013,2014,2015,2016,2017,2018,2019,2020,2027,2032,2040,2041,2042,2043,2044,2045,2046,2047,2048,2050,2051,2052,2053,2054,2055,2056,2057,2058,2062,2063,2066,2067,2069,2070,2071,2072,2073,2074,2075,2076,2082,2083,2084,2085,2086,2087,2088,2089,2090,2091,2092,2093,2094,2095,2096,2097,2098,2099,2100,2101,2102,2103,2104,2105,2106,2107,2108,2109,2110,2111,2112,2113,2114,2115,2116,2117,2119,2120,2121,2122,2123,2124,2125,2126,2127,2128,2129,2130,2131,2132,2133,2134,2135,2136,2137,2138,2139,2140,2141,2142,2143,2144,2145,2146,2147,2148,2149,2150,2151,2152,2153,2154,2155,2156,2157,2158,2159,2160,2161,2162,2163,2164,2165,2166,2167,2168,2169,2170,2171,2172,2173,2174,2175,2176,2177,2178,2179,2180,2181,2182,2183,2184,2185,2186,2206,2209,2210,2211,2212,2213,2214,2215,2217,2218,2219,2220,2221,2222,2223,2224,2225,2226,2227,2229,2230,2231,2232,2244,2245,2246,2247,2250,2251,2252,2253,2254,2255,2256,2257,2258,2259,2260,2261,2262,2263,2264,2265,2266,2267,2268,2269,2270,2271,2272,2273,2274,2275,2276,2277,2278,2279,2280,2281,2282,2283,2294,2295,2296,2297,2298,2299,2300,2301,2302,2303,2306,2307,2308,2309,2310,2311,2312,2313,2314,2315,2317,2318,2319,2320,2321,2322,2323,2324,2325,2328,2330,2331,2332,2333,2335,2336,2337,2338,2340,2341,2342,2343,2344,2345,2346,2347,2348,2349,2351,2352,2362,2363,2364,2365,2366,2367,2368,2369,2370,2371,2372,2373,2374,2375,2376,2377,2378,2379,2380,2382,2383,2384,2385,2386,2387,2388,2389,2390,2391,2392,2393,2394,2395,2396,2398,2399,2400,2401,2402,2403,2404,2405,2406,2407,2408,2409,2410,2411,2412,2413,2414,2415,2416,2417,2418,2419,2420,2421,2422,2423,2424,2425,2426,2427,2428,2429,2430,2431,2432,2433,2434,2435,2436,2437,2438,2439,2440,2441,2442,2443,2444,2445,2446,2447,2448,2449,2450,2451,2452,2453,2454,2455,2456,2457,2458,2459,2460,2461,2462,2463,2464,2465,2466,2467,2468,2469,2470,2471,2472,2473,2474,2475,2476,2477,2478,2479,2480,2481,2482,2483,2484,2485,2486,2487,2488,2489,2490,2491,2492,2496,2497,2500,2501,2505,2506,2507,2508,2515,2516,2519,2520,2521,2522,2523,2524,2528,2529,2530,2531,2533,2535,2536,2546,2549,2551,2552,2553,2554,2555,2556,2557,2558,2559,2560,2561,2562,2563,2564,2565,2566,2577,2578) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/var/folders/_6/468mk1cx3cb080z2r5gq0k_r0000gn/T/ipykernel_9609/2202578721.py:68: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  if X.dtype == np.int or X.dtype == np.int64:\n",
      "/var/folders/_6/468mk1cx3cb080z2r5gq0k_r0000gn/T/ipykernel_9609/2202578721.py:70: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  elif X.dtype == np.float:\n",
      "/var/folders/_6/468mk1cx3cb080z2r5gq0k_r0000gn/T/ipykernel_9609/2202578721.py:72: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  elif X.dtype == np.bool:\n",
      "/var/folders/_6/468mk1cx3cb080z2r5gq0k_r0000gn/T/ipykernel_9609/2202578721.py:74: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  elif X.dtype == np.object:\n"
     ]
    }
   ],
   "source": [
    "data_dir = \".\"\n",
    "df = pd.read_csv(\"{}/mimic4_flat_large.csv\".format(data_dir))\n",
    "df_cols = df.columns.tolist()\n",
    "looking_for = ['heartrate', 'temp', 'systolic', 'diastolic',\n",
    "              'spo2', 'glucose', 'albumin', 'bicarbonate', 'bilirubin',\n",
    "              'creatinine', 'chloride', 'hematocrit', 'hemoglobin', 'lactate',\n",
    "              'magnesium', 'phosphate', 'platelet', 'potassium', 'ptt', 'sodium', 'bun', 'wbc']\n",
    "possible_cols = []\n",
    "for lab_type in df_cols:\n",
    "    for val in looking_for:\n",
    "        if val in lab_type.lower():\n",
    "            possible_cols.append(lab_type)\n",
    "lab_cols = [\n",
    "    'ART BP Diastolic',\n",
    "    'ART BP Systolic',\n",
    "    'Albumin',\n",
    "    'BUN',\n",
    "    'Calcium Chloride',\n",
    "    'Chloride (serum)',\n",
    "    'Creatinine (serum)',\n",
    "    'Glucose (serum)',\n",
    "    'Hematocrit (serum)',\n",
    "    'Hemoglobin',\n",
    "    'Magnesium',\n",
    "    'PTT',\n",
    "    'Platelet Count',\n",
    "    'Potassium (serum)',\n",
    "    'Sodium (serum)',\n",
    "    'Temperature Fahrenheit',\n",
    "    'Total Bilirubin',\n",
    "    'WBC',]\n",
    "df.drop('Communication', axis=1, inplace=True)\n",
    "df_cols = df.columns.tolist()\n",
    "demo_cols = ['admission_type', 'insurance', 'marital_status', 'ethnicity', 'gender', 'age']\n",
    "treatment_cols = df_cols[df_cols.index('mortality')+1:df_cols.index('Insulin - Novolog')+1]\n",
    "treatment_cols = np.array(treatment_cols)[np.sum(df[treatment_cols], axis=0) > 100]\n",
    "\n",
    "X_demo = df[demo_cols]\n",
    "X_treatments = df[treatment_cols]\n",
    "X_labs = df[lab_cols]\n",
    "fill_values = {}\n",
    "for i in range(X_demo.shape[1]):\n",
    "    if X_demo.values[0, i].__class__ == str:\n",
    "        fill_values[i] = 'Missing'\n",
    "    elif X_demo.values[0, i].__class__ == bool:\n",
    "        fill_values[i] = False\n",
    "    elif X_demo.values[0, i].__class__ == float or X_demo.values[0, i].__class__ == int:\n",
    "        fill_values[i] = -1\n",
    "for j in range(X_labs.shape[1]):\n",
    "    if X_labs.values[0, j].__class__ == str:\n",
    "        fill_values[i+j] = 'Missing'\n",
    "    elif X_labs.values[0, j].__class__ == bool:\n",
    "        fill_values[i+j] = False\n",
    "    elif X_labs.values[0, j].__class__ == float or X_labs.values[0, j].__class__ == int:\n",
    "        fill_values[i+j] = -1\n",
    "C = pd.concat([X_demo, X_labs], axis=1).fillna(value=fill_values)\n",
    "\n",
    "for j in range(X_treatments.shape[1]):\n",
    "    if X_treatments.values[0, j].__class__ == str:\n",
    "        fill_values[j] = 'Missing'\n",
    "    elif X_treatments.values[0, j].__class__ == bool:\n",
    "        fill_values[j] = False\n",
    "    elif X_treatments.values[0, j].__class__ == float or X_treatments.values[0, j].__class__ == int:\n",
    "        fill_values[j] = -1\n",
    "X = X_treatments.fillna(value=fill_values)\n",
    "\n",
    "def fillna_unknown_dtype_col(X):\n",
    "    if X.dtype == np.int or X.dtype == np.int64:\n",
    "        X = X.fillna(value=-1)\n",
    "    elif X.dtype == np.float:\n",
    "        X = X.fillna(value=-1)\n",
    "    elif X.dtype == np.bool:\n",
    "        X = X.fillna(value=False)\n",
    "    elif X.dtype == np.object:\n",
    "        X = X.fillna(value='missing')\n",
    "    else:\n",
    "        print(X.dtype)\n",
    "    return X\n",
    "for feat in X.columns:\n",
    "    X[feat] = fillna_unknown_dtype_col(X[feat])\n",
    "for feat in C.columns:\n",
    "    C[feat] = fillna_unknown_dtype_col(C[feat])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic HTE (Heterogeneous Treatment Effect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean survival 0.9261431931016462\n"
     ]
    }
   ],
   "source": [
    "p_covariate = .5  # probability of assigning a patient the new covariate\n",
    "p_treatment = .5  # probability of assigning a patient the new treatment\n",
    "max_pflip_strength = .8  # probability of \"curing\" a patient with the new covariate and new treatment that originally died\n",
    "simulation_type = 'gaussian'  # Map from covariate * treatment to HTE strength\n",
    "\n",
    "Y = df['mortality'].copy().astype(int)\n",
    "y_prior = 1 - np.mean(Y)\n",
    "print(f\"Mean survival {y_prior}\")\n",
    "n = len(Y)\n",
    "pflip_transform = None\n",
    "covariate_vals = None\n",
    "if simulation_type == 'bernoulli':\n",
    "    pflip_transform = lambda covariates: covariates.copy() * max_pflip_strength\n",
    "    covariate_vals = np.array([0, 1])\n",
    "elif simulation_type == 'uniform':\n",
    "    pflip_transform = lambda covariates: covariates.copy() * max_pflip_strength\n",
    "    covariate_vals = np.linspace(.01, 1, 1000)\n",
    "elif simulation_type == 'gaussian':\n",
    "    pflip_transform = lambda x: np.exp(-1/(2*.05)*(x-.5)**2) * max_pflip_strength\n",
    "    covariate_vals = np.linspace(0.01, 1, 1000)\n",
    "pflip_vals = pflip_transform(covariate_vals)\n",
    "\n",
    "idx = np.random.choice(np.arange(len(covariate_vals)), size=n, replace=True) # , p=[1 - p_covariate, p_covariate])\n",
    "covariate = covariate_vals[idx]\n",
    "pflips = pflip_vals[idx]\n",
    "treatment = np.random.binomial(n=1, p=p_treatment, size=n)\n",
    "for i in range(n):\n",
    "    if covariate[i] > 0 and treatment[i] == 1 and Y[i] == 1:\n",
    "        flip = np.random.binomial(n=1, p=pflips[i])\n",
    "        Y[i] -= flip\n",
    "covariate_name = 'New Covariate'\n",
    "treatment_name = 'New Treatment'\n",
    "C[covariate_name] = covariate.astype(float)\n",
    "X[treatment_name] = treatment.astype(float)\n",
    "\n",
    "# Analysis functions\n",
    "def pflip_to_param(p_flip):\n",
    "    odds_prior = y_prior / (1 - y_prior)\n",
    "    y_posterior = y_prior + p_flip * (1 - y_prior)\n",
    "    odds_posterior = y_posterior / (1 - y_posterior)\n",
    "    logodds = np.log(odds_posterior / odds_prior)\n",
    "    return logodds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mise en Place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/correlator/lib/python3.9/site-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "/usr/local/Caskroom/miniconda/base/envs/correlator/lib/python3.9/site-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "/usr/local/Caskroom/miniconda/base/envs/correlator/lib/python3.9/site-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "/usr/local/Caskroom/miniconda/base/envs/correlator/lib/python3.9/site-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "/usr/local/Caskroom/miniconda/base/envs/correlator/lib/python3.9/site-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76540, 90) (76540, 25) (76540, 115)\n"
     ]
    }
   ],
   "source": [
    "# Process data\n",
    "one_hot_encoders = []\n",
    "for feat in C.columns:\n",
    "    try:\n",
    "        C[feat] = C[feat].astype(float)\n",
    "    except:\n",
    "        #C.drop(feat, axis=1, inplace=True)\n",
    "        #continue\n",
    "        enc = OrdinalEncoder()#handle_unknown='ignore')\n",
    "        C[feat] = enc.fit_transform(C[feat].values.reshape(-1, 1))\n",
    "        one_hot_encoders.append(enc)\n",
    "    #print(feat, np.percentile(C[feat].values, 19), np.percentile(C[feat].values, 90))\n",
    "    C[feat].loc[C[feat] > np.percentile(C[feat].values, 99)] = np.percentile(C[feat].values, 99)\n",
    "    C[feat].fillna(-1, inplace=True)\n",
    "\n",
    "X = X.astype(float)\n",
    "for feat in X.columns:\n",
    "    if np.sum(X[feat]) < 100:\n",
    "        X.drop(feat, axis=1, inplace=True)\n",
    "\n",
    "contextual = C.copy()\n",
    "explainable = X.copy()\n",
    "X_full = pd.concat([X, C], axis=1)\n",
    "print(X.shape, C.shape, X_full.shape)\n",
    "C_train, C_test, X_train, X_test, X_all_train, X_all_test, mortality_train, mortality_test = train_test_split(\n",
    "    contextual, explainable, X_full, Y.astype(float), test_size=0.25)\n",
    "C_means = np.mean(C_train, axis=0)\n",
    "C_stds  = np.std(C_train, axis=0)\n",
    "C_train = (C_train - C_means) / C_stds\n",
    "C_test  = (C_test  - C_means) / C_stds\n",
    "C_train = C_train.loc[:, C_stds > 0.1]  # removes Calcium Chloride covariate\n",
    "C_test  = C_test.loc[:, C_stds > 0.1]\n",
    "\n",
    "covariate_i = C_train.columns.tolist().index(covariate_name)\n",
    "treatment_i = X_train.columns.tolist().index(treatment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explainable Boosting Machine (baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EBM Train AUROC:\t0.9088257651044838\n",
      "EBM Train F1:\t\t0.2706875753920386\n",
      "EBM Test AUROC:\t\t0.8910881230039902\n",
      "EBM Test F1:\t\t0.26215022091310747\n",
      "EBM L2:\t\t\t0.9121528696554778\n"
     ]
    }
   ],
   "source": [
    "# EBM\n",
    "# look for all treatment-covariate interactions\n",
    "interactions = list(product(range(treatment_i + 1), range(treatment_i + 1, (treatment_i + 1) + (covariate_i + 1)  + 1)))\n",
    "ebm_hte = ebc(outer_bags=1, interactions=interactions, max_bins=32) \n",
    "ebm_hte.fit(X_all_train, mortality_train)\n",
    "# Get estimated weights\n",
    "feat_i = ebm_hte.get_params()['feature_names'].index(f\"{treatment_name} x {covariate_name}\")\n",
    "explanation = ebm_hte.explain_global().data(feat_i)\n",
    "weights = np.array(explanation['scores'])\n",
    "hte_est = weights[1] - weights[0]\n",
    "hte_est -= hte_est[0]  # center\n",
    "cov_vals = np.array(explanation['right_names']).astype(float)\n",
    "if len(cov_vals) > 2:\n",
    "    cov_vals = (cov_vals[1:] + cov_vals[:-1]) / 2  # middle of bin\n",
    "pflip_true = pflip_transform(cov_vals) \n",
    "hte_true = pflip_to_param(pflip_true)\n",
    "# Evaluate\n",
    "ebm_train_auroc = roc(mortality_train,  ebm_hte.predict_proba(X_all_train)[:, 1])\n",
    "ebm_train_f1 = f1_score(mortality_train, ebm_hte.predict(X_all_train))\n",
    "ebm_test_auroc = roc(mortality_test,  ebm_hte.predict_proba(X_all_test)[:, 1])\n",
    "ebm_test_f1 = f1_score(mortality_test, ebm_hte.predict(X_all_test))\n",
    "ebm_l2_hte = ((hte_true - hte_est)**2).mean()\n",
    "print(f\"EBM Train AUROC:\\t{ebm_train_auroc}\")\n",
    "print(f\"EBM Train F1:\\t\\t{ebm_train_f1}\")\n",
    "print(f\"EBM Test AUROC:\\t\\t{ebm_test_auroc}\")\n",
    "print(f\"EBM Test F1:\\t\\t{ebm_test_f1}\")\n",
    "print(f\"EBM L2:\\t\\t\\t{ebm_l2_hte}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/correlator/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Train AUROC:\t0.9096169859951208\n",
      "Log Train F1:\t\t0.3294930875576037\n",
      "Log Test AUROC:\t\t0.8514194649092176\n",
      "Log Test F1:\t\t0.23712067748764995\n",
      "Log L2:\t\t\t0.7818690184669947\n"
     ]
    }
   ],
   "source": [
    "# Logsitic\n",
    "def get_paired_df(X_df, Y_df):\n",
    "    XY_header = []\n",
    "    XY_values = []\n",
    "    for X_col in X_df.columns:\n",
    "        for Y_col in Y_df.columns:\n",
    "            XY_col = f\"{X_col} x {Y_col}\"\n",
    "            XY_vals = X_df[X_col] * Y_df[Y_col]\n",
    "            XY_header.append(XY_col)\n",
    "            XY_values.append(XY_vals)\n",
    "    XY_values = np.array(XY_values).T\n",
    "    # pd.concat fails to join, here's a workaround\n",
    "    full_header = X_df.columns.tolist() + Y_df.columns.tolist() + XY_header\n",
    "    full_values = np.concatenate((X_df.values, Y_df.values, XY_values), axis=1)\n",
    "    return pd.DataFrame(data=full_values, columns=full_header)\n",
    "\n",
    "X_paired_train = get_paired_df(C_train, X_train)\n",
    "X_paired_test = get_paired_df(C_test, X_test)\n",
    "interaction_i = X_paired_train.columns.tolist().index('New Covariate x New Treatment')\n",
    "\n",
    "logistic = LogisticRegression(penalty='none')\n",
    "logistic.fit(X_paired_train, mortality_train)\n",
    "logistic_coef = logistic.coef_[0, interaction_i]\n",
    "hte_est = logistic_coef * covariate_vals\n",
    "hte_true = pflip_to_param(pflip_vals)\n",
    "\n",
    "logistic_train_auroc = roc(mortality_train, logistic.predict_proba(X_paired_train)[:, 1])\n",
    "logistic_train_f1 = f1_score(mortality_train, logistic.predict(X_paired_train))\n",
    "logistic_test_auroc = roc(mortality_test, logistic.predict_proba(X_paired_test)[:, 1])\n",
    "logistic_test_f1 = f1_score(mortality_test, logistic.predict(X_paired_test))\n",
    "logistic_l2_hte = ((hte_true - hte_est)**2).mean()\n",
    "print(f\"Log Train AUROC:\\t{logistic_train_auroc}\")\n",
    "print(f\"Log Train F1:\\t\\t{logistic_train_f1}\")\n",
    "print(f\"Log Test AUROC:\\t\\t{logistic_test_auroc}\")\n",
    "print(f\"Log Test F1:\\t\\t{logistic_test_f1}\")\n",
    "print(f\"Log L2:\\t\\t\\t{logistic_l2_hte}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/calebellington/Workbench/ContextualizedCorrelator/contextualized/regression.py:128: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.C = torch.tensor(C, dtype=dtype, device=device)\n",
      "/Users/calebellington/Workbench/ContextualizedCorrelator/contextualized/regression.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.X = torch.tensor(X, dtype=dtype, device=device)\n",
      "/Users/calebellington/Workbench/ContextualizedCorrelator/contextualized/regression.py:130: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.Y = torch.tensor(Y, dtype=dtype, device=device)\n",
      "[Train MSE:   0.0000] [Sample: 57404/57405]: 100%|â–ˆ| 1/1 [12:09<00:00, 729.92\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import trange\n",
    "from contextualized.regression import NGAM, MultivariateDataset\n",
    "\n",
    "C_train_t = torch.tensor(C_train.values, dtype=torch.float)\n",
    "X_train_t_pre = torch.tensor(X_train.values, dtype=torch.float)\n",
    "X_train_t = torch.cat((X_train_t_pre, torch.ones(X_train_t_pre.shape[0], 1)), dim=1)\n",
    "Y_train_t = torch.tensor(mortality_train.values, dtype=torch.float).unsqueeze(-1)\n",
    "C_test_t = torch.tensor(C_test.values, dtype=torch.float)\n",
    "X_test_t_pre = torch.tensor(X_test.values, dtype=torch.float)\n",
    "X_test_t = torch.cat((X_test_t_pre, torch.ones(X_test_t_pre.shape[0], 1)), dim=1)\n",
    "Y_test_t = torch.tensor(mortality_test.values, dtype=torch.float).unsqueeze(-1)\n",
    "\n",
    "mse = lambda y_hat, y: (y_hat - y).pow(2).mean()\n",
    "sigmoid = lambda x: 1 / (1 + torch.exp(-x))\n",
    "ngam = NGAM(C_train_t.shape[-1], X_train_t.shape[-1], width=100, layers=3)\n",
    "opt = torch.optim.Adam(ngam.parameters(), lr=1e-4)\n",
    "\n",
    "epochs = 1\n",
    "batch_size = 2\n",
    "train_dataset = MultivariateDataset(C_train_t, X_train_t, Y_train_t, batch_size=batch_size)\n",
    "progress_bar = tqdm(range(epochs))\n",
    "for _ in progress_bar:\n",
    "    for batch_i, (c, _, x, y) in enumerate(train_dataset):\n",
    "        w = ngam(c)\n",
    "        y_hat = sigmoid((w * x).sum(dim=1).squeeze())\n",
    "        loss = mse(y_hat, y.squeeze())\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        train_desc = f'[Train MSE: {loss.item():8.4f}] [Sample: {batch_size * batch_i}/{len(train_dataset)}]'\n",
    "        progress_bar.set_description(train_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CGAM Train AUROC:\t0.8573239175825433\n",
      "CGAM Train F1:\t\t0.17815646785437644\n",
      "CGAM Test AUROC:\t0.8527916283390218\n",
      "CGAM Test F1:\t\t0.17795275590551182\n",
      "CGAM L2:\t\t0.9016688276012631\n"
     ]
    }
   ],
   "source": [
    "train_preds = sigmoid((X_train_t * ngam(C_train_t)).sum(dim=1)).squeeze().detach().numpy()\n",
    "test_preds = sigmoid((X_test_t * ngam(C_test_t)).sum(dim=1)).squeeze().detach().numpy()\n",
    "feature_model = ngam.nams[covariate_i]\n",
    "covariate_inputs = (covariate_vals - C_means[covariate_name]) / C_stds[covariate_name]\n",
    "feature_in = torch.tensor(covariate_inputs, dtype=torch.float).unsqueeze(-1)\n",
    "feature_out = feature_model(feature_in).detach().numpy()\n",
    "hte_est = feature_out[:,treatment_i]\n",
    "hte_true = pflip_to_param(pflip_vals)\n",
    "\n",
    "cgam_train_auroc = roc(mortality_train, train_preds)\n",
    "cgam_train_f1 = f1_score(mortality_train, np.round(train_preds))\n",
    "cgam_test_auroc = roc(mortality_test, test_preds)\n",
    "cgam_test_f1 = f1_score(mortality_test, np.round(test_preds))\n",
    "cgam_l2_hte = ((hte_true - hte_est)**2).mean()\n",
    "print(f\"CGAM Train AUROC:\\t{cgam_train_auroc}\")\n",
    "print(f\"CGAM Train F1:\\t\\t{cgam_train_f1}\")\n",
    "print(f\"CGAM Test AUROC:\\t{cgam_test_auroc}\")\n",
    "print(f\"CGAM Test F1:\\t\\t{cgam_test_f1}\")\n",
    "print(f\"CGAM L2:\\t\\t{cgam_l2_hte}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:correlator]",
   "language": "python",
   "name": "conda-env-correlator-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
